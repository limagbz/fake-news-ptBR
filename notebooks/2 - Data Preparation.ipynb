{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to change the data format from multiple files to a CSV file with all the needed information. To use this notebook correctly we need to do some initial configurations such as the paths of the data (see below). Here we will be using the full text dataset (i.e. the data that is not truncated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_FOLDER = Path('data/raw/')\n",
    "INTERMEDIATE_DATA_FOLDER = Path('data/interim/')\n",
    "REFERENCE_FOLDER = Path('references/')\n",
    "\n",
    "FAKE_DATA_FOLDER = RAW_DATA_FOLDER / 'fake'\n",
    "TRUE_DATA_FOLDER = RAW_DATA_FOLDER / 'true'\n",
    "FAKE_META_FOLDER = RAW_DATA_FOLDER / 'fake-meta-information'\n",
    "TRUE_META_FOLDER = RAW_DATA_FOLDER / 'true-meta-information'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start with the text data. For this we will create a dataframe with each text as a cell of a column. This will need a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_df(folder):\n",
    "    df_dict = {}\n",
    "    for filepath in folder.glob(\"*.txt\"):\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            df_dict[filepath.stem] = f.read() \n",
    "    return pd.DataFrame.from_dict(df_dict, orient='index', columns=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create the text datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_text_df = create_text_df(FAKE_DATA_FOLDER)\n",
    "true_text_df = create_text_df(TRUE_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>Dória manda recado para Lula: \"Justiça foi fei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081</th>\n",
       "      <td>Em vídeo, Eduardo Bolsonaro se revolta: \"Nomea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>Míssil ICBM da Coreia pode atingir o Havaii e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>Vídeo da NASA mostra OVNI reabastecendo suas e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>Presídio de Alcaçuz: Não houve invasão da PM. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "1030  Dória manda recado para Lula: \"Justiça foi fei...\n",
       "3081  Em vídeo, Eduardo Bolsonaro se revolta: \"Nomea...\n",
       "1316  Míssil ICBM da Coreia pode atingir o Havaii e ...\n",
       "834   Vídeo da NASA mostra OVNI reabastecendo suas e...\n",
       "1691  Presídio de Alcaçuz: Não houve invasão da PM. ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the \"text data\" section we need to do the same here for metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata_df(folder, metadata_columns):\n",
    "    df_dict = {}\n",
    "    df_dict = {k:[] for k in metadata_columns}\n",
    "    df_dict[\"index\"] = []\n",
    "    \n",
    "    for filepath in list(folder.glob(\"*.txt\")):\n",
    "        with open(filepath, 'r') as f:    \n",
    "            df_dict[\"index\"].append(filepath.stem.split(\"-\")[0])\n",
    "            for col, value in zip(metadata_columns, f.readlines()):\n",
    "                df_dict[col].append(value[0:-1])\n",
    "    \n",
    "    df = pd.DataFrame(df_dict)\n",
    "    df.index.name = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the dataset folders, we can see that the values of the columns are defined by the an order defined on the README file. The order is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = [\n",
    "    \"author\", \"link\", \"category\", \"date_of_publication\",\n",
    "    \"tokens\", \"words_no_punctuation\", \"types\", \"links_inside\", \n",
    "    \"upper_words\", \"verbs\", \"subjuntive_imperative_verbs\",\n",
    "    \"nouns\", \"adjectives\", \"adverbs\", \"modal_verbs\", \n",
    "    \"singular_first_second_personal_pronouns\",\n",
    "    \"plural_first_personal_pronouns\", \"pronouns\",\n",
    "    \"pausality\", \"characters\", \"average_sentence_length\",\n",
    "    \"average_word_lenght\", \"percentage_spelling_errors\",\n",
    "    \"emotiveness\", \"diversity\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_metadata_df = create_metadata_df(FAKE_META_FOLDER, metadata_columns)\n",
    "true_metadata_df = create_metadata_df(TRUE_META_FOLDER, metadata_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "      <th>date_of_publication</th>\n",
       "      <th>tokens</th>\n",
       "      <th>words_no_punctuation</th>\n",
       "      <th>types</th>\n",
       "      <th>links_inside</th>\n",
       "      <th>upper_words</th>\n",
       "      <th>verbs</th>\n",
       "      <th>...</th>\n",
       "      <th>plural_first_personal_pronouns</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>pausality</th>\n",
       "      <th>characters</th>\n",
       "      <th>average_sentence_length</th>\n",
       "      <th>average_word_lenght</th>\n",
       "      <th>percentage_spelling_errors</th>\n",
       "      <th>emotiveness</th>\n",
       "      <th>diversity</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>https://www.diariodobrasil.org/senador-que-ass...</td>\n",
       "      <td>politica</td>\n",
       "      <td>06/12/2016</td>\n",
       "      <td>642</td>\n",
       "      <td>548</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>127</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>1.84314</td>\n",
       "      <td>2428</td>\n",
       "      <td>10.7451</td>\n",
       "      <td>4.43066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234818</td>\n",
       "      <td>0.49087</td>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>https://www.diariodobrasil.org/pirou-de-vez-lu...</td>\n",
       "      <td>politica</td>\n",
       "      <td>10/10/2017</td>\n",
       "      <td>159</td>\n",
       "      <td>136</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.91667</td>\n",
       "      <td>574</td>\n",
       "      <td>11.3333</td>\n",
       "      <td>4.22059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.63970</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>https://www.diariodobrasil.org/lava-jato-inves...</td>\n",
       "      <td>politica</td>\n",
       "      <td>31/08/2016</td>\n",
       "      <td>289</td>\n",
       "      <td>259</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.72727</td>\n",
       "      <td>1278</td>\n",
       "      <td>23.5455</td>\n",
       "      <td>4.93436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168067</td>\n",
       "      <td>0.61003</td>\n",
       "      <td>2228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>https://www.diariodobrasil.org/ministerio-publ...</td>\n",
       "      <td>politica</td>\n",
       "      <td>02/04/2017</td>\n",
       "      <td>170</td>\n",
       "      <td>152</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>729</td>\n",
       "      <td>16.8889</td>\n",
       "      <td>4.79605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.69736</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>https://www.diariodobrasil.org/video-mostra-fr...</td>\n",
       "      <td>sociedade_cotidiano</td>\n",
       "      <td>21/03/2017</td>\n",
       "      <td>166</td>\n",
       "      <td>146</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.85714</td>\n",
       "      <td>740</td>\n",
       "      <td>20.8571</td>\n",
       "      <td>5.06849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.75342</td>\n",
       "      <td>1456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  author                                               link  \\\n",
       "0   None  https://www.diariodobrasil.org/senador-que-ass...   \n",
       "1   None  https://www.diariodobrasil.org/pirou-de-vez-lu...   \n",
       "2   None  https://www.diariodobrasil.org/lava-jato-inves...   \n",
       "3   None  https://www.diariodobrasil.org/ministerio-publ...   \n",
       "4   None  https://www.diariodobrasil.org/video-mostra-fr...   \n",
       "\n",
       "              category date_of_publication tokens words_no_punctuation types  \\\n",
       "0             politica          06/12/2016    642                  548   269   \n",
       "1             politica          10/10/2017    159                  136    87   \n",
       "2             politica          31/08/2016    289                  259   158   \n",
       "3             politica          02/04/2017    170                  152   106   \n",
       "4  sociedade_cotidiano          21/03/2017    166                  146   110   \n",
       "\n",
       "  links_inside upper_words verbs  ... plural_first_personal_pronouns pronouns  \\\n",
       "0            0          30   127  ...                              2       69   \n",
       "1            0           3    38  ...                              0       20   \n",
       "2            0          10    37  ...                              0        9   \n",
       "3            0           9    18  ...                              0        4   \n",
       "4            0           1    28  ...                              0        6   \n",
       "\n",
       "  pausality characters average_sentence_length average_word_lenght  \\\n",
       "0   1.84314       2428                 10.7451             4.43066   \n",
       "1   1.91667        574                 11.3333             4.22059   \n",
       "2   2.72727       1278                 23.5455             4.93436   \n",
       "3       2.0        729                 16.8889             4.79605   \n",
       "4   2.85714        740                 20.8571             5.06849   \n",
       "\n",
       "  percentage_spelling_errors emotiveness diversity index  \n",
       "0                        0.0    0.234818   0.49087  1863  \n",
       "1                        0.0      0.1875   0.63970   630  \n",
       "2                        0.0    0.168067   0.61003  2228  \n",
       "3                        0.0    0.220588   0.69736  1412  \n",
       "4                        0.0    0.186667   0.75342  1456  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the data we can see that some columns have a string \"None\" instead of a np.nan. This can be seen in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528\n",
      "1393\n"
     ]
    }
   ],
   "source": [
    "print(len(fake_metadata_df[fake_metadata_df.isin([\"None\"]).any(axis=1)]))\n",
    "print(len(true_metadata_df[true_metadata_df.isin([\"None\"]).any(axis=1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix this by replacing the values of \"None\" by np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_metadata_df = fake_metadata_df.replace(\"None\", np.nan)\n",
    "true_metadata_df = true_metadata_df.replace(\"None\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let's correct the data types. Here we need to specify the data types manually based on the information provided by the documentation. \n",
    "\n",
    "**NOTE:** the variable *date_of_publication* have a lot of different formats that cannot be idenfitified by the pandas library, this variable will be corrected later. In this case we define here as a string variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dtypes = {\n",
    "    \"author\": \"string\", \"link\": \"string\", \"category\": \"string\",\n",
    "    \"date_of_publication\": \"string\",\n",
    "    \"tokens\": \"float\", \"words_no_punctuation\": \"float\",\n",
    "    \"types\": \"float\",\"links_inside\": \"float\", \"upper_words\": \"float\",\n",
    "    \"verbs\": \"float\", \"subjuntive_imperative_verbs\": \"float\", \"nouns\": \"float\", \n",
    "    \"adjectives\": \"float\", \"adverbs\": \"float\",\"modal_verbs\": \"float\", \n",
    "    \"singular_first_second_personal_pronouns\": \"float\",\n",
    "    \"plural_first_personal_pronouns\": \"float\", \"pronouns\": \"float\",\"characters\": \"float\",\n",
    "    \"pausality\": \"float\", \"average_sentence_length\": \"float\",\n",
    "    \"average_word_lenght\": \"float\", \"percentage_spelling_errors\": \"float\",\n",
    "    \"emotiveness\": \"float\", \"diversity\": \"float\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_metadata_df = fake_metadata_df.astype(metadata_dtypes, errors='raise').set_index(\"index\", drop=True)\n",
    "true_metadata_df = true_metadata_df.astype(metadata_dtypes, errors='raise').set_index(\"index\", drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just need to merge the created datasets. First the metadata with the texts and than both datasets to create a unique csv file with all the information that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = pd.concat([fake_text_df, fake_metadata_df], axis=1, sort=False)\n",
    "fake_df.index = fake_df.index.astype(int)\n",
    "fake_df = fake_df.reset_index().rename(columns={\"index\": \"file_index\"})\n",
    "fake_df = fake_df.sort_index()\n",
    "\n",
    "true_df = pd.concat([true_text_df, true_metadata_df], axis=1, sort=False)\n",
    "true_df.index = true_df.index.astype(int)\n",
    "true_df = true_df.reset_index().rename(columns={\"index\": \"file_index\"})\n",
    "true_df = true_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([true_df, fake_df], keys=['True', 'Fake'])\n",
    "result = result.reset_index(level=0)\n",
    "result = result.rename(columns={\"level_0\": \"class\"})\n",
    "result.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class', 'file_index', 'text', 'author', 'link', 'category',\n",
       "       'date_of_publication', 'tokens', 'words_no_punctuation', 'types',\n",
       "       'links_inside', 'upper_words', 'verbs', 'subjuntive_imperative_verbs',\n",
       "       'nouns', 'adjectives', 'adverbs', 'modal_verbs',\n",
       "       'singular_first_second_personal_pronouns',\n",
       "       'plural_first_personal_pronouns', 'pronouns', 'pausality', 'characters',\n",
       "       'average_sentence_length', 'average_word_lenght',\n",
       "       'percentage_spelling_errors', 'emotiveness', 'diversity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERMEDIATE_DATA_FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "result.to_csv(INTERMEDIATE_DATA_FOLDER/ \"fake_true_news.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
