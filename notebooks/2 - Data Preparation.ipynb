{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to change the data format from multiple files to a CSV file with all the needed information. To use this notebook correctly we need to do some initial configurations such as the paths of the data (see below). Here we will be using the full text dataset (i.e. the data that is not truncated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_FOLDER = Path('data/raw/')\n",
    "INTERMEDIATE_DATA_FOLDER = Path('data/interim/')\n",
    "REFERENCE_FOLDER = Path('references/')\n",
    "\n",
    "FAKE_DATA_FOLDER = RAW_DATA_FOLDER / 'fake'\n",
    "TRUE_DATA_FOLDER = RAW_DATA_FOLDER / 'true'\n",
    "FAKE_META_FOLDER = RAW_DATA_FOLDER / 'fake-meta-information'\n",
    "TRUE_META_FOLDER = RAW_DATA_FOLDER / 'true-meta-information'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start with the text data. For this we will create a dataframe with each text as a cell of a column. This will need a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_df(folder):\n",
    "    df_dict = {}\n",
    "    for filepath in folder.glob(\"*.txt\"):\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            df_dict[filepath.stem] = f.read() \n",
    "    return pd.DataFrame.from_dict(df_dict, orient='index', columns=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create the text datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_text_df = create_text_df(FAKE_DATA_FOLDER)\n",
    "true_text_df = create_text_df(TRUE_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Legalização do trabalho escravo no Brasil será...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>Assad bate de frente com Trump e declara: \" Nã...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Temer vai punir Sergio Reis e Tiririca por tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>Jornalista diz que Dilma pode estar trabalhand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>Lula tropeça nas palavras: \"Serei candidato co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "118   Legalização do trabalho escravo no Brasil será...\n",
       "1365  Assad bate de frente com Trump e declara: \" Nã...\n",
       "34    Temer vai punir Sergio Reis e Tiririca por tra...\n",
       "3080  Jornalista diz que Dilma pode estar trabalhand...\n",
       "722   Lula tropeça nas palavras: \"Serei candidato co..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the \"text data\" section we need to do the same here for metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata_df(folder, metadata_columns):\n",
    "    df_dict = {}\n",
    "    df_dict = {k:[] for k in metadata_columns}\n",
    "    df_dict[\"index\"] = []\n",
    "    \n",
    "    for filepath in list(folder.glob(\"*.txt\")):\n",
    "        with open(filepath, 'r') as f:    \n",
    "            df_dict[\"index\"].append(filepath.stem.split(\"-\")[0])\n",
    "            for col, value in zip(metadata_columns, f.readlines()):\n",
    "                df_dict[col].append(value[0:-1])\n",
    "    \n",
    "    df = pd.DataFrame(df_dict)\n",
    "    df.index.name = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the dataset folders, we can see that the values of the columns are defined by the an order defined on the README file. The order is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = [\n",
    "    \"author\", \"link\", \"category\", \"date_of_publication\",\n",
    "    \"tokens\", \"words_no_punctuation\", \"types\", \"links_inside\", \n",
    "    \"upper_words\", \"verbs\", \"subjuntive_imperative_verbs\",\n",
    "    \"nouns\", \"adjectives\", \"adverbs\", \"modal_verbs\", \n",
    "    \"singular_first_second_personal_pronouns\",\n",
    "    \"plural_first_personal_pronouns\", \"pronouns\",\n",
    "    \"pausality\", \"characters\", \"average_sentence_length\",\n",
    "    \"average_word_lenght\", \"percentage_spelling_errors\",\n",
    "    \"emotiveness\", \"diversity\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_metadata_df = create_metadata_df(FAKE_META_FOLDER, metadata_columns)\n",
    "true_metadata_df = create_metadata_df(TRUE_META_FOLDER, metadata_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "      <th>date_of_publication</th>\n",
       "      <th>tokens</th>\n",
       "      <th>words_no_punctuation</th>\n",
       "      <th>types</th>\n",
       "      <th>links_inside</th>\n",
       "      <th>upper_words</th>\n",
       "      <th>verbs</th>\n",
       "      <th>...</th>\n",
       "      <th>plural_first_personal_pronouns</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>pausality</th>\n",
       "      <th>characters</th>\n",
       "      <th>average_sentence_length</th>\n",
       "      <th>average_word_lenght</th>\n",
       "      <th>percentage_spelling_errors</th>\n",
       "      <th>emotiveness</th>\n",
       "      <th>diversity</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>https://www.diariodobrasil.org/pedido-de-prisa...</td>\n",
       "      <td>politica</td>\n",
       "      <td>03/05/2016</td>\n",
       "      <td>242</td>\n",
       "      <td>220</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.83333</td>\n",
       "      <td>1003</td>\n",
       "      <td>18.3333</td>\n",
       "      <td>4.55909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.57272</td>\n",
       "      <td>2867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>https://www.diariodobrasil.org/porque-a-minist...</td>\n",
       "      <td>sociedade_cotidiano</td>\n",
       "      <td>14/09/2016</td>\n",
       "      <td>293</td>\n",
       "      <td>250</td>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1246</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.984</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.66</td>\n",
       "      <td>2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>https://www.diariodobrasil.org/os-principais-b...</td>\n",
       "      <td>politica</td>\n",
       "      <td>10/12/2016</td>\n",
       "      <td>423</td>\n",
       "      <td>332</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.39474</td>\n",
       "      <td>1490</td>\n",
       "      <td>8.73684</td>\n",
       "      <td>4.48795</td>\n",
       "      <td>0.0060241</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.53915</td>\n",
       "      <td>1834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>https://www.diariodobrasil.org/todos-os-corean...</td>\n",
       "      <td>sociedade_cotidiano</td>\n",
       "      <td>06/09/2017</td>\n",
       "      <td>307</td>\n",
       "      <td>270</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3.08333</td>\n",
       "      <td>1334</td>\n",
       "      <td>22.5</td>\n",
       "      <td>4.94074</td>\n",
       "      <td>0.0037037</td>\n",
       "      <td>0.243697</td>\n",
       "      <td>0.58148</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>https://www.diariodobrasil.org/cantora-elza-so...</td>\n",
       "      <td>sociedade_cotidiano</td>\n",
       "      <td>06/08/2017</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.66667</td>\n",
       "      <td>167</td>\n",
       "      <td>11.6667</td>\n",
       "      <td>4.77143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0588235</td>\n",
       "      <td>0.94285</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  author                                               link  \\\n",
       "0   None  https://www.diariodobrasil.org/pedido-de-prisa...   \n",
       "1   None  https://www.diariodobrasil.org/porque-a-minist...   \n",
       "2   None  https://www.diariodobrasil.org/os-principais-b...   \n",
       "3   None  https://www.diariodobrasil.org/todos-os-corean...   \n",
       "4   None  https://www.diariodobrasil.org/cantora-elza-so...   \n",
       "\n",
       "              category date_of_publication tokens words_no_punctuation types  \\\n",
       "0             politica          03/05/2016    242                  220   126   \n",
       "1  sociedade_cotidiano          14/09/2016    293                  250   167   \n",
       "2             politica          10/12/2016    423                  332   179   \n",
       "3  sociedade_cotidiano          06/09/2017    307                  270   157   \n",
       "4  sociedade_cotidiano          06/08/2017     43                   35    33   \n",
       "\n",
       "  links_inside upper_words verbs  ... plural_first_personal_pronouns pronouns  \\\n",
       "0            0           4    33  ...                              0        2   \n",
       "1            1           2    36  ...                              0       17   \n",
       "2            1          68    37  ...                              0        7   \n",
       "3            1           9    42  ...                              0       14   \n",
       "4            0           0     4  ...                              0        2   \n",
       "\n",
       "  pausality characters average_sentence_length average_word_lenght  \\\n",
       "0   1.83333       1003                 18.3333             4.55909   \n",
       "1       4.3       1246                    25.0               4.984   \n",
       "2   2.39474       1490                 8.73684             4.48795   \n",
       "3   3.08333       1334                    22.5             4.94074   \n",
       "4   2.66667        167                 11.6667             4.77143   \n",
       "\n",
       "  percentage_spelling_errors emotiveness diversity index  \n",
       "0                        0.0    0.147059   0.57272  2867  \n",
       "1                      0.012    0.376238      0.66  2175  \n",
       "2                  0.0060241      0.0625   0.53915  1834  \n",
       "3                  0.0037037    0.243697   0.58148   825  \n",
       "4                        0.0   0.0588235   0.94285   961  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fake_metadata_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the data we can see that some columns have a string \"None\" instead of a np.nan. This can be seen in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528\n",
      "1393\n"
     ]
    }
   ],
   "source": [
    "print(len(fake_metadata_df[fake_metadata_df.isin([\"None\"]).any(axis=1)]))\n",
    "print(len(true_metadata_df[true_metadata_df.isin([\"None\"]).any(axis=1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix this by replacing the values of \"None\" by np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_metadata_df = fake_metadata_df.replace(\"None\", np.nan)\n",
    "true_metadata_df = true_metadata_df.replace(\"None\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let's correct the data types. Here we need to specify the data types manually based on the information provided by the documentation. \n",
    "\n",
    "**NOTE:** the variable *date_of_publication* have a lot of different formats that cannot be idenfitified by the pandas library, this variable will be corrected later. In this case we define here as a string variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dtypes = {\n",
    "    \"author\": \"string\", \"link\": \"string\", \"category\": \"string\",\n",
    "    \"date_of_publication\": \"string\",\n",
    "    \"tokens\": \"float\", \"words_no_punctuation\": \"float\",\n",
    "    \"types\": \"float\",\"links_inside\": \"float\", \"upper_words\": \"float\",\n",
    "    \"verbs\": \"float\", \"subjuntive_imperative_verbs\": \"float\", \"nouns\": \"float\", \n",
    "    \"adjectives\": \"float\", \"adverbs\": \"float\",\"modal_verbs\": \"float\", \n",
    "    \"singular_first_second_personal_pronouns\": \"float\",\n",
    "    \"plural_first_personal_pronouns\": \"float\", \"pronouns\": \"float\",\"characters\": \"float\",\n",
    "    \"pausality\": \"float\", \"average_sentence_length\": \"float\",\n",
    "    \"average_word_lenght\": \"float\", \"percentage_spelling_errors\": \"float\",\n",
    "    \"emotiveness\": \"float\", \"diversity\": \"float\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_metadata_df = fake_metadata_df.astype(metadata_dtypes, errors='raise').set_index(\"index\", drop=True)\n",
    "true_metadata_df = true_metadata_df.astype(metadata_dtypes, errors='raise').set_index(\"index\", drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: DATETIME TRANSFORMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just need to merge the created datasets. First the metadata with the texts and than both datasets to create a unique csv file with all the information that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = pd.concat([fake_text_df, fake_metadata_df], axis=1, sort=False)\n",
    "fake_df.index = fake_df.index.astype(int)\n",
    "fake_df = fake_df.reset_index().rename(columns={\"index\": \"file_index\"})\n",
    "fake_df = fake_df.sort_index()\n",
    "\n",
    "true_df = pd.concat([true_text_df, true_metadata_df], axis=1, sort=False)\n",
    "true_df.index = true_df.index.astype(int)\n",
    "true_df = true_df.reset_index().rename(columns={\"index\": \"file_index\"})\n",
    "true_df = true_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([true_df, fake_df], keys=['True', 'Fake'])\n",
    "result = result.reset_index(level=0)\n",
    "result = result.rename(columns={\"level_0\": \"class\"})\n",
    "result.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class', 'file_index', 'text', 'author', 'link', 'category',\n",
       "       'date_of_publication', 'tokens', 'words_no_punctuation', 'types',\n",
       "       'links_inside', 'upper_words', 'verbs', 'subjuntive_imperative_verbs',\n",
       "       'nouns', 'adjectives', 'adverbs', 'modal_verbs',\n",
       "       'singular_first_second_personal_pronouns',\n",
       "       'plural_first_personal_pronouns', 'pronouns', 'pausality', 'characters',\n",
       "       'average_sentence_length', 'average_word_lenght',\n",
       "       'percentage_spelling_errors', 'emotiveness', 'diversity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERMEDIATE_DATA_FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "result.to_csv(INTERMEDIATE_DATA_FOLDER/ \"fake_true_news.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
