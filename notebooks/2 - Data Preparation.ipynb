{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to change the data format from multiple files to a CSV file with all the needed information. To use this notebook correctly we need to do some initial configurations such as the paths of the data (see below). Here we will be using the full text dataset (i.e. the data that is not truncated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_FOLDER = Path('data/raw/')\n",
    "INTERMEDIATE_DATA_FOLDER = Path('data/interim/')\n",
    "REFERENCE_FOLDER = Path('references/')\n",
    "\n",
    "FAKE_DATA_FOLDER = RAW_DATA_FOLDER / 'fake'\n",
    "TRUE_DATA_FOLDER = RAW_DATA_FOLDER / 'true'\n",
    "FAKE_META_FOLDER = RAW_DATA_FOLDER / 'fake-meta-information'\n",
    "TRUE_META_FOLDER = RAW_DATA_FOLDER / 'true-meta-information'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start with the text data. For this we will create a dataframe with each text as a cell of a column. This will need a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_df(folder):\n",
    "    df_dict = {}\n",
    "    for filepath in folder.glob(\"*.txt\"):\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            df_dict[filepath.stem] = f.read() \n",
    "    return pd.DataFrame.from_dict(df_dict, orient='index', columns=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create the text datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_text_df = create_text_df(FAKE_DATA_FOLDER)\n",
    "true_text_df = create_text_df(TRUE_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kátia Abreu diz que vai colocar sua expulsão e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dr. Ray peita Bolsonaro, chama-o de conservad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Reinaldo Azevedo desmascarado pela Polícia Fed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Relatório assustador do BNDES mostra dinheiro ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>Radialista americano fala sobre o PT: \"Eles ve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "1     Kátia Abreu diz que vai colocar sua expulsão e...\n",
       "10    Dr. Ray peita Bolsonaro, chama-o de conservad...\n",
       "100   Reinaldo Azevedo desmascarado pela Polícia Fed...\n",
       "1000  Relatório assustador do BNDES mostra dinheiro ...\n",
       "1001  Radialista americano fala sobre o PT: \"Eles ve..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the \"text data\" section we need to do the same here for metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata_df(folder, metadata_columns):\n",
    "    df_dict = {}\n",
    "    df_dict = {k:[] for k in metadata_columns}\n",
    "    df_dict[\"index\"] = []\n",
    "    \n",
    "    for filepath in list(folder.glob(\"*.txt\")):\n",
    "        with open(filepath, 'r') as f:    \n",
    "            df_dict[\"index\"].append(filepath.stem.split(\"-\")[0])\n",
    "            for col, value in zip(metadata_columns, f.readlines()):\n",
    "                df_dict[col].append(value[0:-1])\n",
    "    \n",
    "    df = pd.DataFrame(df_dict)\n",
    "    df.index.name = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the dataset folders, we can see that the values of the columns are defined by the an order defined on the README file. The order is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = [\n",
    "    \"author\", \"link\", \"category\", \"date_of_publication\",\n",
    "    \"tokens\", \"words_no_punctuation\", \"types\", \"links_inside\", \n",
    "    \"upper_words\", \"verbs\", \"subjuntive_imperative_verbs\",\n",
    "    \"nouns\", \"adjectives\", \"adverbs\", \"modal_verbs\", \n",
    "    \"singular_first_second_personal_pronouns\",\n",
    "    \"plural_first_personal_pronouns\", \"pronouns\",\n",
    "    \"pausality\", \"characters\", \"average_sentence_length\",\n",
    "    \"average_word_lenght\", \"percentage_spelling_errors\",\n",
    "    \"emotiveness\", \"diversity\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_metadata_df = create_metadata_df(FAKE_META_FOLDER, metadata_columns)\n",
    "true_metadata_df = create_metadata_df(TRUE_META_FOLDER, metadata_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "      <th>date_of_publication</th>\n",
       "      <th>tokens</th>\n",
       "      <th>words_no_punctuation</th>\n",
       "      <th>types</th>\n",
       "      <th>links_inside</th>\n",
       "      <th>upper_words</th>\n",
       "      <th>verbs</th>\n",
       "      <th>...</th>\n",
       "      <th>plural_first_personal_pronouns</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>pausality</th>\n",
       "      <th>characters</th>\n",
       "      <th>average_sentence_length</th>\n",
       "      <th>average_word_lenght</th>\n",
       "      <th>percentage_spelling_errors</th>\n",
       "      <th>emotiveness</th>\n",
       "      <th>diversity</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mrk</td>\n",
       "      <td>https://ceticismopolitico.com/2017/11/30/katia...</td>\n",
       "      <td>politica</td>\n",
       "      <td>2017-11-30</td>\n",
       "      <td>211</td>\n",
       "      <td>185</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>815</td>\n",
       "      <td>14.2308</td>\n",
       "      <td>4.40541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.64864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>https://ceticismopolitico.com/2017/11/24/dr-ra...</td>\n",
       "      <td>politica</td>\n",
       "      <td>2017-11-24</td>\n",
       "      <td>289</td>\n",
       "      <td>254</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1205</td>\n",
       "      <td>18.1429</td>\n",
       "      <td>4.74409</td>\n",
       "      <td>0.00787402</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.64173</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>https://afolhabrasil.com.br/politica/reinaldo-...</td>\n",
       "      <td>politica</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>304</td>\n",
       "      <td>275</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.8125</td>\n",
       "      <td>1344</td>\n",
       "      <td>17.1875</td>\n",
       "      <td>4.88727</td>\n",
       "      <td>0.00363636</td>\n",
       "      <td>0.12782</td>\n",
       "      <td>0.61818</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>https://www.diariodobrasil.org/relatorio-assus...</td>\n",
       "      <td>politica</td>\n",
       "      <td>24/07/2017</td>\n",
       "      <td>639</td>\n",
       "      <td>572</td>\n",
       "      <td>316</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3122</td>\n",
       "      <td>22.88</td>\n",
       "      <td>5.45804</td>\n",
       "      <td>0.00174825</td>\n",
       "      <td>0.229008</td>\n",
       "      <td>0.55244</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>https://www.diariodobrasil.org/radialista-amer...</td>\n",
       "      <td>politica</td>\n",
       "      <td>25/07/2017</td>\n",
       "      <td>128</td>\n",
       "      <td>111</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>515</td>\n",
       "      <td>5.84211</td>\n",
       "      <td>4.63964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.73873</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  author                                               link  category  \\\n",
       "0    mrk  https://ceticismopolitico.com/2017/11/30/katia...  politica   \n",
       "1   None  https://ceticismopolitico.com/2017/11/24/dr-ra...  politica   \n",
       "2   None  https://afolhabrasil.com.br/politica/reinaldo-...  politica   \n",
       "3   None  https://www.diariodobrasil.org/relatorio-assus...  politica   \n",
       "4   None  https://www.diariodobrasil.org/radialista-amer...  politica   \n",
       "\n",
       "  date_of_publication tokens words_no_punctuation types links_inside  \\\n",
       "0          2017-11-30    211                  185   120            0   \n",
       "1          2017-11-24    289                  254   163            0   \n",
       "2          2017-05-23    304                  275   170            0   \n",
       "3          24/07/2017    639                  572   316            1   \n",
       "4          25/07/2017    128                  111    82            0   \n",
       "\n",
       "  upper_words verbs  ... plural_first_personal_pronouns pronouns pausality  \\\n",
       "0           6    30  ...                              0       26       2.0   \n",
       "1           0    56  ...                              0       20       2.5   \n",
       "2           0    45  ...                              0       18    1.8125   \n",
       "3          14    87  ...                              0       34      2.68   \n",
       "4           1    21  ...                              0       12  0.894737   \n",
       "\n",
       "  characters average_sentence_length average_word_lenght  \\\n",
       "0        815                 14.2308             4.40541   \n",
       "1       1205                 18.1429             4.74409   \n",
       "2       1344                 17.1875             4.88727   \n",
       "3       3122                   22.88             5.45804   \n",
       "4        515                 5.84211             4.63964   \n",
       "\n",
       "  percentage_spelling_errors emotiveness diversity index  \n",
       "0                        0.0    0.263158   0.64864     1  \n",
       "1                 0.00787402    0.241667   0.64173    10  \n",
       "2                 0.00363636     0.12782   0.61818   100  \n",
       "3                 0.00174825    0.229008   0.55244  1000  \n",
       "4                        0.0    0.269231   0.73873  1001  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fake_metadata_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the data we can see that some columns have a string \"None\" instead of a np.nan. This can be seen in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528\n",
      "1393\n"
     ]
    }
   ],
   "source": [
    "print(len(fake_metadata_df[fake_metadata_df.isin([\"None\"]).any(axis=1)]))\n",
    "print(len(true_metadata_df[true_metadata_df.isin([\"None\"]).any(axis=1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix this by replacing the values of \"None\" by np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_metadata_df = fake_metadata_df.replace(\"None\", np.nan)\n",
    "true_metadata_df = true_metadata_df.replace(\"None\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let's correct the data types. Here we need to specify the data types manually based on the information provided by the documentation. \n",
    "\n",
    "**NOTE:** the variable *date_of_publication* have a lot of different formats that cannot be idenfitified by the pandas library, this variable will be corrected later. In this case we define here as a string variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dtypes = {\n",
    "    \"author\": \"string\", \"link\": \"string\", \"category\": \"string\",\n",
    "    \"date_of_publication\": \"string\",\n",
    "    \"tokens\": \"float\", \"words_no_punctuation\": \"float\",\n",
    "    \"types\": \"float\",\"links_inside\": \"float\", \"upper_words\": \"float\",\n",
    "    \"verbs\": \"float\", \"subjuntive_imperative_verbs\": \"float\", \"nouns\": \"float\", \n",
    "    \"adjectives\": \"float\", \"adverbs\": \"float\",\"modal_verbs\": \"float\", \n",
    "    \"singular_first_second_personal_pronouns\": \"float\",\n",
    "    \"plural_first_personal_pronouns\": \"float\", \"pronouns\": \"float\",\"characters\": \"float\",\n",
    "    \"pausality\": \"float\", \"average_sentence_length\": \"float\",\n",
    "    \"average_word_lenght\": \"float\", \"percentage_spelling_errors\": \"float\",\n",
    "    \"emotiveness\": \"float\", \"diversity\": \"float\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_metadata_df = fake_metadata_df.astype(metadata_dtypes, errors='raise').set_index(\"index\", drop=True)\n",
    "true_metadata_df = true_metadata_df.astype(metadata_dtypes, errors='raise').set_index(\"index\", drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: DATETIME TRANSFORMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just need to merge the created datasets. First the metadata with the texts and than both datasets to create a unique csv file with all the information that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = pd.concat([fake_text_df, fake_metadata_df], axis=1, sort=False)\n",
    "fake_df.index = fake_df.index.astype(int)\n",
    "fake_df = fake_df.reset_index().rename(columns={\"index\": \"file_index\"})\n",
    "fake_df = fake_df.sort_index()\n",
    "\n",
    "true_df = pd.concat([true_text_df, true_metadata_df], axis=1, sort=False)\n",
    "true_df.index = true_df.index.astype(int)\n",
    "true_df = true_df.reset_index().rename(columns={\"index\": \"file_index\"})\n",
    "true_df = true_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([true_df, fake_df], keys=['True', 'Fake'])\n",
    "result = result.reset_index(level=0)\n",
    "result = result.rename(columns={\"level_0\": \"class\"})\n",
    "result.index.name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERMEDIATE_DATA_FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "result.to_csv(INTERMEDIATE_DATA_FOLDER/ \"fake_true_news.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
